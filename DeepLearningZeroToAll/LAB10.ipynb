{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LAB10.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM1zGCCHkVviCVf2jiGsk5y"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"htIAVP-gEa1C","executionInfo":{"status":"ok","timestamp":1612619428021,"user_tz":-540,"elapsed":33473,"user":{"displayName":"­기수민(스크랜튼대학 융합학부)","photoUrl":"","userId":"04800909769003208371"}},"outputId":"23022cc4-a3a6-48ee-dea5-3391a3b6b86a"},"source":["pip install tensorflow==1.0.0"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/58/b71480f9ec9d08d581d672a81b15ab5fec36a5fcda2093558a23614d8468/tensorflow-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (44.5MB)\n","\u001b[K     |████████████████████████████████| 44.5MB 97kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.0.0) (1.19.5)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.0.0) (0.36.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.0.0) (1.15.0)\n","Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.0.0) (3.12.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.1.0->tensorflow==1.0.0) (53.0.0)\n","Installing collected packages: tensorflow\n","  Found existing installation: tensorflow 2.4.1\n","    Uninstalling tensorflow-2.4.1:\n","      Successfully uninstalled tensorflow-2.4.1\n","Successfully installed tensorflow-1.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wl9h1QQhIg7q","executionInfo":{"status":"ok","timestamp":1612612719193,"user_tz":-540,"elapsed":48665,"user":{"displayName":"­기수민(스크랜튼대학 융합학부)","photoUrl":"","userId":"04800909769003208371"}},"outputId":"d2118779-24b8-41e1-bc5d-8876dd778ff6"},"source":["# Softmax classifier for MNIST\r\n","import tensorflow as tf\r\n","import matplotlib.pyplot as plt\r\n","import random\r\n","from tensorflow.examples.tutorials.mnist import input_data\r\n","tf.set_random_seed(777) #reproducibility\r\n","\r\n","mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\r\n","\r\n","# input place holders\r\n","X = tf.placeholder(tf.float32, [None, 784])\r\n","Y = tf.placeholder(tf.float32, [None, 10])\r\n","\r\n","# weights & bias for nn layers\r\n","W = tf.Variable(tf.random_normal([784, 10]))\r\n","b = tf.Variable(tf.random_normal([10]))\r\n","hypothesis = tf.matmul(X, W) + b\r\n","\r\n","# parameters\r\n","learning_rate = 0.001\r\n","batch_size = 100\r\n","num_epochs = 50\r\n","num_iterations = int(mnist.train.num_examples / batch_size)\r\n","\r\n","# define cost/loss & optimizer\r\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = hypothesis, labels = Y))\r\n","optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\r\n","# initialize\r\n","sess = tf.Session()\r\n","sess.run(tf.global_variables_initializer())\r\n","\r\n","# train my model\r\n","for epoch in range(num_epochs):\r\n","  avg_cost = 0\r\n","  total_batch = int(mnist.train.num_examples / batch_size)\r\n","\r\n","  for i in range(num_iterations):\r\n","    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\r\n","    feed_dict = {X: batch_xs, Y: batch_ys}\r\n","    c, _ = sess.run([cost, optimizer], feed_dict = feed_dict)\r\n","    avg_cost += c / total_batch\r\n","\r\n","  print('Epoch: ', '%04d' %(epoch + 1), 'cost', '{:.9f}'.format(avg_cost))\r\n","print('Learning Finished!')\r\n","\r\n","  # Test model and check accuracy\r\n","correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\r\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\n","print('Accuracy: ', sess.run(accuracy, feed_dict = {X: mnist.test.images, Y: mnist.test.labels}))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Extracting MNIST_data/train-images-idx3-ubyte.gz\n","Extracting MNIST_data/train-labels-idx1-ubyte.gz\n","Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n","Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n","Epoch:  0001 cost 5.163796400\n","Epoch:  0002 cost 1.797224067\n","Epoch:  0003 cost 1.193830018\n","Epoch:  0004 cost 0.940557948\n","Epoch:  0005 cost 0.797898133\n","Epoch:  0006 cost 0.704181432\n","Epoch:  0007 cost 0.638274748\n","Epoch:  0008 cost 0.588618289\n","Epoch:  0009 cost 0.549795883\n","Epoch:  0010 cost 0.519363513\n","Epoch:  0011 cost 0.493809832\n","Epoch:  0012 cost 0.472177533\n","Epoch:  0013 cost 0.453691709\n","Epoch:  0014 cost 0.438605635\n","Epoch:  0015 cost 0.424315347\n","Epoch:  0016 cost 0.412059950\n","Epoch:  0017 cost 0.400706910\n","Epoch:  0018 cost 0.391323129\n","Epoch:  0019 cost 0.382312766\n","Epoch:  0020 cost 0.374555438\n","Epoch:  0021 cost 0.366589518\n","Epoch:  0022 cost 0.359666627\n","Epoch:  0023 cost 0.353659451\n","Epoch:  0024 cost 0.347528791\n","Epoch:  0025 cost 0.342094278\n","Epoch:  0026 cost 0.337166237\n","Epoch:  0027 cost 0.332238708\n","Epoch:  0028 cost 0.328102215\n","Epoch:  0029 cost 0.324408096\n","Epoch:  0030 cost 0.320249495\n","Epoch:  0031 cost 0.316505459\n","Epoch:  0032 cost 0.313517589\n","Epoch:  0033 cost 0.310164387\n","Epoch:  0034 cost 0.306995058\n","Epoch:  0035 cost 0.304595781\n","Epoch:  0036 cost 0.301236686\n","Epoch:  0037 cost 0.298485660\n","Epoch:  0038 cost 0.296276312\n","Epoch:  0039 cost 0.294007911\n","Epoch:  0040 cost 0.291697549\n","Epoch:  0041 cost 0.289162261\n","Epoch:  0042 cost 0.288064483\n","Epoch:  0043 cost 0.285779484\n","Epoch:  0044 cost 0.283800704\n","Epoch:  0045 cost 0.281721432\n","Epoch:  0046 cost 0.279997779\n","Epoch:  0047 cost 0.278180867\n","Epoch:  0048 cost 0.277079901\n","Epoch:  0049 cost 0.275348494\n","Epoch:  0050 cost 0.273944588\n","Learning Finished!\n","Accuracy:  0.9195\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wNP9LUddOHzV","executionInfo":{"status":"ok","timestamp":1612617030974,"user_tz":-540,"elapsed":115715,"user":{"displayName":"­기수민(스크랜튼대학 융합학부)","photoUrl":"","userId":"04800909769003208371"}},"outputId":"3ab871a4-633d-4699-fa71-2a52a642986d"},"source":["# MNIST with NN\r\n","import tensorflow as tf\r\n","import random\r\n","from tensorflow.examples.tutorials.mnist import input_data\r\n","\r\n","tf.set_random_seed(777)\r\n","\r\n","mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\r\n","\r\n","# parameters\r\n","learning_rate = 0.001\r\n","training_epochs = 15\r\n","batch_size = 100\r\n","\r\n","# input place holders\r\n","X = tf.placeholder(tf.float32, [None, 784])\r\n","Y = tf.placeholder(tf.float32, [None, 10])\r\n","\r\n","# weight & bias for nn layers\r\n","W1 = tf.Variable(tf.random_normal([784, 256]))\r\n","b1 = tf.Variable(tf.random_normal([256]))\r\n","L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\r\n","\r\n","W2 = tf.Variable(tf.random_normal([256, 256]))\r\n","b2 = tf.Variable(tf.random_normal([256]))\r\n","L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\r\n","\r\n","W3 = tf.Variable(tf.random_normal([256, 10]))\r\n","b3 = tf.Variable(tf.random_normal([10]))\r\n","hypothesis = tf.matmul(L2, W3) + b3\r\n","\r\n","# define cost/loss & optimizer\r\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits= hypothesis, labels = Y))\r\n","optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\r\n","\r\n","# initialize\r\n","sess = tf.Session()\r\n","sess.run(tf.global_variables_initializer())\r\n","\r\n","# train my model\r\n","for epoch in range(training_epochs):\r\n","  avg_cost = 0\r\n","  total_batch = int(mnist.train.num_examples / batch_size)\r\n","\r\n","  for i in range(total_batch):\r\n","    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\r\n","    feed_dict = {X: batch_xs, Y: batch_ys}\r\n","    c, _ = sess.run([cost, optimizer], feed_dict = feed_dict)\r\n","    avg_cost += c / total_batch\r\n","\r\n","  print('Epoch: ', '%04d' % (epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost))\r\n","print('Learning Finished!')\r\n","\r\n","# Test model and check accuracy\r\n","correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\r\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\n","print('Accuracy: ', sess.run(accuracy, feed_dict = {X: mnist.test.images, Y: mnist.test.labels}))\r\n","\r\n","# Get one and predict\r\n","r = random.randint(0, mnist.test.num_examples - 1)\r\n","print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r: r + 1], 1)))\r\n","print(\"Prediction: \", sess.run(tf.argmax(hypothesis, 1), feed_dict = {X: mnist.test.images[r: r + 1]}))\r\n"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Extracting MNIST_data/train-images-idx3-ubyte.gz\n","Extracting MNIST_data/train-labels-idx1-ubyte.gz\n","Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n","Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n","Epoch:  0001 cost =  179.630085213\n","Epoch:  0002 cost =  45.935357430\n","Epoch:  0003 cost =  28.965186540\n","Epoch:  0004 cost =  20.242837973\n","Epoch:  0005 cost =  14.794988041\n","Epoch:  0006 cost =  10.949570505\n","Epoch:  0007 cost =  8.338718821\n","Epoch:  0008 cost =  6.206909734\n","Epoch:  0009 cost =  4.820110909\n","Epoch:  0010 cost =  3.563429860\n","Epoch:  0011 cost =  2.685109765\n","Epoch:  0012 cost =  2.080839932\n","Epoch:  0013 cost =  1.546757600\n","Epoch:  0014 cost =  1.264605141\n","Epoch:  0015 cost =  0.927126900\n","Learning Finished!\n","Accuracy:  0.943\n","Label:  [0]\n","Prediction:  [0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GWAE0Eevef1g","executionInfo":{"status":"ok","timestamp":1612617531642,"user_tz":-540,"elapsed":115074,"user":{"displayName":"­기수민(스크랜튼대학 융합학부)","photoUrl":"","userId":"04800909769003208371"}},"outputId":"48ab4a32-8e8c-4f95-bec8-07f9ced4d4b5"},"source":["# Xavier for MNIST\r\n","import tensorflow as tf\r\n","import random\r\n","from tensorflow.examples.tutorials.mnist import input_data\r\n","\r\n","tf.set_random_seed(777)\r\n","\r\n","mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\r\n","\r\n","# parameters\r\n","learning_rate = 0.001\r\n","training_epochs = 15\r\n","batch_size = 100\r\n","\r\n","# input place holders\r\n","X = tf.placeholder(tf.float32, [None, 784])\r\n","Y = tf.placeholder(tf.float32, [None, 10])\r\n","\r\n","# weight & bias for nn layers\r\n","# initializer with xavier\r\n","W1 = tf.get_variable(\"W1\", shape=[784, 256], initializer=tf.contrib.layers.xavier_initializer())\r\n","b1 = tf.Variable(tf.random_normal([256]))\r\n","L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\r\n","\r\n","W2 = tf.get_variable(\"W2\", shape=[256, 256], initializer=tf.contrib.layers.xavier_initializer())\r\n","b2 = tf.Variable(tf.random_normal([256]))\r\n","L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\r\n","\r\n","W3 = tf.get_variable(\"W3\", shape=[256, 10], initializer=tf.contrib.layers.xavier_initializer())\r\n","b3 = tf.Variable(tf.random_normal([10]))\r\n","hypothesis = tf.matmul(L2, W3) + b3\r\n","\r\n","# define cost/loss & optimizer\r\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits= hypothesis, labels = Y))\r\n","optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\r\n","\r\n","# initialize\r\n","sess = tf.Session()\r\n","sess.run(tf.global_variables_initializer())\r\n","\r\n","# train my model\r\n","for epoch in range(training_epochs):\r\n","  avg_cost = 0\r\n","  total_batch = int(mnist.train.num_examples / batch_size)\r\n","\r\n","  for i in range(total_batch):\r\n","    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\r\n","    feed_dict = {X: batch_xs, Y: batch_ys}\r\n","    c, _ = sess.run([cost, optimizer], feed_dict = feed_dict)\r\n","    avg_cost += c / total_batch\r\n","\r\n","  print('Epoch: ', '%04d' % (epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost))\r\n","print('Learning Finished!')\r\n","\r\n","# Test model and check accuracy\r\n","correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\r\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\n","print('Accuracy: ', sess.run(accuracy, feed_dict = {X: mnist.test.images, Y: mnist.test.labels}))\r\n","\r\n","# Get one and predict\r\n","r = random.randint(0, mnist.test.num_examples - 1)\r\n","print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r: r + 1], 1)))\r\n","print(\"Prediction: \", sess.run(tf.argmax(hypothesis, 1), feed_dict = {X: mnist.test.images[r: r + 1]}))\r\n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Extracting MNIST_data/train-images-idx3-ubyte.gz\n","Extracting MNIST_data/train-labels-idx1-ubyte.gz\n","Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n","Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n","Epoch:  0001 cost =  0.354681734\n","Epoch:  0002 cost =  0.120263674\n","Epoch:  0003 cost =  0.076988531\n","Epoch:  0004 cost =  0.057307916\n","Epoch:  0005 cost =  0.044011583\n","Epoch:  0006 cost =  0.033366467\n","Epoch:  0007 cost =  0.025534245\n","Epoch:  0008 cost =  0.022421076\n","Epoch:  0009 cost =  0.017912907\n","Epoch:  0010 cost =  0.013809434\n","Epoch:  0011 cost =  0.015835449\n","Epoch:  0012 cost =  0.012546074\n","Epoch:  0013 cost =  0.010454479\n","Epoch:  0014 cost =  0.009697323\n","Epoch:  0015 cost =  0.009449028\n","Learning Finished!\n","Accuracy:  0.977\n","Label:  [3]\n","Prediction:  [3]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WpS7Cryhf6Z1","executionInfo":{"status":"ok","timestamp":1612618656190,"user_tz":-540,"elapsed":505367,"user":{"displayName":"­기수민(스크랜튼대학 융합학부)","photoUrl":"","userId":"04800909769003208371"}},"outputId":"5941ad21-a26a-4362-af1c-5cc0a57f1464"},"source":["# Xavier for MNIST (Deep)\r\n","import tensorflow as tf\r\n","import random\r\n","from tensorflow.examples.tutorials.mnist import input_data\r\n","\r\n","tf.set_random_seed(777)\r\n","\r\n","mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\r\n","\r\n","# parameters\r\n","learning_rate = 0.001\r\n","training_epochs = 15\r\n","batch_size = 100\r\n","\r\n","# input place holders\r\n","X = tf.placeholder(tf.float32, [None, 784])\r\n","Y = tf.placeholder(tf.float32, [None, 10])\r\n","\r\n","# weight & bias for nn layers\r\n","# initializer with xavier\r\n","W1 = tf.get_variable(\"W1\", shape=[784, 512], initializer=tf.contrib.layers.xavier_initializer())\r\n","b1 = tf.Variable(tf.random_normal([512]))\r\n","L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\r\n","\r\n","W2 = tf.get_variable(\"W2\", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())\r\n","b2 = tf.Variable(tf.random_normal([512]))\r\n","L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\r\n","\r\n","W3 = tf.get_variable(\"W3\", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())\r\n","b3 = tf.Variable(tf.random_normal([512]))\r\n","L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\r\n","\r\n","W4 = tf.get_variable(\"W4\", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())\r\n","b4 = tf.Variable(tf.random_normal([512]))\r\n","L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\r\n","\r\n","W5 = tf.get_variable(\"W5\", shape=[512, 10], initializer=tf.contrib.layers.xavier_initializer())\r\n","b5 = tf.Variable(tf.random_normal([10]))\r\n","hypothesis = tf.matmul(L4, W5) + b5\r\n","\r\n","# define cost/loss & optimizer\r\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits= hypothesis, labels = Y))\r\n","optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\r\n","\r\n","# initialize\r\n","sess = tf.Session()\r\n","sess.run(tf.global_variables_initializer())\r\n","\r\n","# train my model\r\n","for epoch in range(training_epochs):\r\n","  avg_cost = 0\r\n","  total_batch = int(mnist.train.num_examples / batch_size)\r\n","\r\n","  for i in range(total_batch):\r\n","    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\r\n","    feed_dict = {X: batch_xs, Y: batch_ys}\r\n","    c, _ = sess.run([cost, optimizer], feed_dict = feed_dict)\r\n","    avg_cost += c / total_batch\r\n","\r\n","  print('Epoch: ', '%04d' % (epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost))\r\n","print('Learning Finished!')\r\n","\r\n","# Test model and check accuracy\r\n","correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\r\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\n","print('Accuracy: ', sess.run(accuracy, feed_dict = {X: mnist.test.images, Y: mnist.test.labels}))\r\n","\r\n","# Get one and predict\r\n","r = random.randint(0, mnist.test.num_examples - 1)\r\n","print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r: r + 1], 1)))\r\n","print(\"Prediction: \", sess.run(tf.argmax(hypothesis, 1), feed_dict = {X: mnist.test.images[r: r + 1]}))\r\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:474: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:475: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n"],"name":"stderr"},{"output_type":"stream","text":["Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n","Extracting MNIST_data/train-images-idx3-ubyte.gz\n","Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n","Extracting MNIST_data/train-labels-idx1-ubyte.gz\n","Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n","Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n","Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n","Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n","Epoch:  0001 cost =  0.312538976\n","Epoch:  0002 cost =  0.103358163\n","Epoch:  0003 cost =  0.073835991\n","Epoch:  0004 cost =  0.054777496\n","Epoch:  0005 cost =  0.045503541\n","Epoch:  0006 cost =  0.034840105\n","Epoch:  0007 cost =  0.028716639\n","Epoch:  0008 cost =  0.028936179\n","Epoch:  0009 cost =  0.023198847\n","Epoch:  0010 cost =  0.019060912\n","Epoch:  0011 cost =  0.019945441\n","Epoch:  0012 cost =  0.017985628\n","Epoch:  0013 cost =  0.017768133\n","Epoch:  0014 cost =  0.014944907\n","Epoch:  0015 cost =  0.013556705\n","Learning Finished!\n","Accuracy:  0.9792\n","Label:  [4]\n","Prediction:  [4]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iy8Z4KR_mMYW","executionInfo":{"status":"ok","timestamp":1612620289064,"user_tz":-540,"elapsed":500102,"user":{"displayName":"­기수민(스크랜튼대학 융합학부)","photoUrl":"","userId":"04800909769003208371"}},"outputId":"d1662c59-2dee-4dc8-872a-a2f2df102516"},"source":["# Xavier for MNIST (Dropout)\r\n","import tensorflow as tf\r\n","import random\r\n","from tensorflow.examples.tutorials.mnist import input_data\r\n","\r\n","tf.set_random_seed(777)\r\n","\r\n","mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\r\n","\r\n","# parameters\r\n","learning_rate = 0.001\r\n","training_epochs = 15\r\n","batch_size = 100\r\n","\r\n","# input place holders\r\n","X = tf.placeholder(tf.float32, [None, 784])\r\n","Y = tf.placeholder(tf.float32, [None, 10])\r\n","\r\n","# dropout (keep_prob) rate 0.7 on training, but should be 1 for testing\r\n","keep_prob = tf.placeholder(tf.float32)\r\n","\r\n","# weight & bias for nn layers\r\n","# initializer with xavier\r\n","W1 = tf.get_variable(\"W1\", shape=[784, 512], initializer=tf.contrib.layers.xavier_initializer())\r\n","b1 = tf.Variable(tf.random_normal([512]))\r\n","L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\r\n","L1 = tf.nn.dropout(L1, keep_prob = keep_prob)\r\n","\r\n","W2 = tf.get_variable(\"W2\", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())\r\n","b2 = tf.Variable(tf.random_normal([512]))\r\n","L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\r\n","L2 = tf.nn.dropout(L2, keep_prob = keep_prob)\r\n","\r\n","W3 = tf.get_variable(\"W3\", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())\r\n","b3 = tf.Variable(tf.random_normal([512]))\r\n","L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\r\n","L3 = tf.nn.dropout(L3, keep_prob = keep_prob)\r\n","\r\n","W4 = tf.get_variable(\"W4\", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())\r\n","b4 = tf.Variable(tf.random_normal([512]))\r\n","L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\r\n","L4 = tf.nn.dropout(L4, keep_prob = keep_prob)\r\n","\r\n","W5 = tf.get_variable(\"W5\", shape=[512, 10], initializer=tf.contrib.layers.xavier_initializer())\r\n","b5 = tf.Variable(tf.random_normal([10]))\r\n","hypothesis = tf.matmul(L4, W5) + b5\r\n","\r\n","# define cost/loss & optimizer\r\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits= hypothesis, labels = Y))\r\n","optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\r\n","\r\n","# initialize\r\n","sess = tf.Session()\r\n","sess.run(tf.global_variables_initializer())\r\n","\r\n","# train my model\r\n","for epoch in range(training_epochs):\r\n","  avg_cost = 0\r\n","  total_batch = int(mnist.train.num_examples / batch_size)\r\n","\r\n","  for i in range(total_batch):\r\n","    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\r\n","    feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\r\n","    c, _ = sess.run([cost, optimizer], feed_dict = feed_dict)\r\n","    avg_cost += c / total_batch\r\n","\r\n","  print('Epoch: ', '%04d' % (epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost))\r\n","print('Learning Finished!')\r\n","\r\n","# Test model and check accuracy\r\n","correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\r\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\n","print('Accuracy: ', sess.run(accuracy, feed_dict = {X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\r\n","\r\n","# Get one and predict\r\n","r = random.randint(0, mnist.test.num_examples - 1)\r\n","print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r: r + 1], 1)))\r\n","print(\"Prediction: \", sess.run(tf.argmax(hypothesis, 1), feed_dict = {X: mnist.test.images[r: r + 1], keep_prob: 1}))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:474: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:475: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n"],"name":"stderr"},{"output_type":"stream","text":["Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n","Extracting MNIST_data/train-images-idx3-ubyte.gz\n","Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n","Extracting MNIST_data/train-labels-idx1-ubyte.gz\n","Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n","Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n","Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n","Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n","Epoch:  0001 cost =  0.467784753\n","Epoch:  0002 cost =  0.175405254\n","Epoch:  0003 cost =  0.128736291\n","Epoch:  0004 cost =  0.110615291\n","Epoch:  0005 cost =  0.094717075\n","Epoch:  0006 cost =  0.084929243\n","Epoch:  0007 cost =  0.076213265\n","Epoch:  0008 cost =  0.071058962\n","Epoch:  0009 cost =  0.063642122\n","Epoch:  0010 cost =  0.061395054\n","Epoch:  0011 cost =  0.056704394\n","Epoch:  0012 cost =  0.053259362\n","Epoch:  0013 cost =  0.047940605\n","Epoch:  0014 cost =  0.046457986\n","Epoch:  0015 cost =  0.048081206\n","Learning Finished!\n","Accuracy:  0.9823\n","Label:  [6]\n","Prediction:  [6]\n"],"name":"stdout"}]}]}